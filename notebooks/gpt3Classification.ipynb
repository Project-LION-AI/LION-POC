{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dm8zWXwbgji2"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3A86NGVnggCt"
      },
      "outputs": [],
      "source": [
        "#data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import spacy\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import empath\n",
        "import networkx\n",
        "import email"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SkqKRhsgsi-"
      },
      "source": [
        "## CSV Train method\n",
        "\n",
        "you shouldn't need to run this since openai saves the trained model for you on its server and you can just call that model instead of the based model, but this is good for reference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWXXz1Abglnl"
      },
      "outputs": [],
      "source": [
        "#data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "emo_path='../data/emotions_train.txt'\n",
        "train_data = pd.read_csv(emo_path, sep=';')\n",
        "#convert to true dataframe\n",
        "corpus = pd.DataFrame(train_data)\n",
        "\n",
        "#prepare training file\n",
        "corpus.to_csv('emo_corpus.csv', index=False)\n",
        "\n",
        "prep_corpus = pd.read_csv('emo_corpus.csv')\n",
        "\n",
        "prep_corpus = prep_corpus[['completion','prompt']]\n",
        "\n",
        "prep_corpus.to_csv('emo_prep_corpus.csv', index=False)\n",
        "\n",
        "\n",
        "prep_corpus.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXahw-NvhE_W"
      },
      "source": [
        "Here is where you will point gpt-3 to the jsonl file you want to train on. It will output a fileID that you will use in the model params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh19zqHQhAy7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = \"key\"\n",
        "openai.File.create(\n",
        "  file=open(\"../data/emo_prep_corpus_prepared.jsonl\"),\n",
        "  purpose='classifications'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeIF3RxChUhq"
      },
      "source": [
        "This is how to use your fine-tuned gpt-3 model with the `file` param"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_AFJxdIhRxc"
      },
      "outputs": [],
      "source": [
        "#classify function\n",
        "def trained_gpt_classify(query):\n",
        "  response = openai.Classification.create(\n",
        "        search_model=\"ada\",\n",
        "        model=\"curie\",\n",
        "        query=query,\n",
        "        file='file-AACA1lEnh7BmrqiiS3EL1WVQ',\n",
        "        max_examples=3\n",
        "      )\n",
        "  return response.label\n",
        "\n",
        "query = 'I love my life!'\n",
        "\n",
        "test = trained_gpt_classify(query)\n",
        "\n",
        "print(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx9AdWZKholx"
      },
      "source": [
        "Here I iterate through the test set and classify each one, save the results to a new column, and compare the differences. Note that these path names will need to change and we will need to either upload the files or mount google drive. I will share a drive folder with the needed files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLbWsI8UhhxJ"
      },
      "outputs": [],
      "source": [
        "emo_test_path='../data/emotions_test.txt'\n",
        "\n",
        "test_data = pd.read_csv(emo_test_path, sep=';')\n",
        "\n",
        "#convert to true dataframe\n",
        "corpus = pd.DataFrame(test_data)\n",
        "\n",
        "#first try a subset\n",
        "corpus_subset = corpus.loc[:100]\n",
        "\n",
        "#iterate and classify\n",
        "for i, row in corpus_subset.iterrows():\n",
        "    query = row['prompt']\n",
        "    test = trained_gpt_classify(query)\n",
        "    corpus_subset.at[i, 'prediction'] = test\n",
        "\n",
        "#output to csv\n",
        "#corpus.to_csv('emo_test_results.csv', index=False)\n",
        "\n",
        "#make prediction column lowercase\n",
        "corpus_subset['prediction'] = corpus_subset['prediction'].str.lower()\n",
        "\n",
        "#check for differences between prediction and completion columns\n",
        "corpus_subset['diff'] = np.nan\n",
        "for i, row in corpus_subset.iterrows():\n",
        "    if corpus_subset.at[i, 'prediction'] == corpus_subset.at[i, 'completion']:\n",
        "        corpus_subset.at[i, 'diff'] = 1\n",
        "    else:\n",
        "        corpus_subset.at[i, 'diff'] = 0\n",
        "\n",
        "#show top 50 results\n",
        "corpus_subset.head(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QY5q5qFh5wQ"
      },
      "source": [
        "Take a look at the results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jwwz-XPh7CH"
      },
      "outputs": [],
      "source": [
        "#sum all of the differences\n",
        "total_correct = corpus_subset['diff'].sum()\n",
        "#print total_correct\n",
        "print(total_correct)\n",
        "\n",
        "#percent correct\n",
        "percent_correct = total_correct / len(corpus_subset)\n",
        "\n",
        "#print percent correct\n",
        "print(percent_correct)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv8NR_u-h-oq"
      },
      "source": [
        "view incorrect preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQdAs398h_o8"
      },
      "outputs": [],
      "source": [
        "#view dataframe of incorrect predictions\n",
        "incorrect_predictions = corpus_subset[corpus_subset['diff'] == 0]\n",
        "incorrect_predictions.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmonbPQxiEsj"
      },
      "outputs": [],
      "source": [
        "#count the number of rows where the prediction was 'unknown'\n",
        "unknown_predictions = incorrect_predictions[incorrect_predictions['prediction'] == 'unknown']\n",
        "unknown_predictions.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bWY5cXpiGsv"
      },
      "outputs": [],
      "source": [
        "#try to reclassify some of these as one offs\n",
        "\n",
        "#pick a random prompt from unknown_predictions\n",
        "query = unknown_predictions['prompt'][np.random.randint(0, unknown_predictions.shape[0])]\n",
        "\n",
        "print('query:',query)\n",
        "print()\n",
        "print('completion: ')\n",
        "trained_gpt_classify(query)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GPT-3_Classification_Example.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
